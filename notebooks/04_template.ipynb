{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/retinanet_pet_detector/blob/master/notebooks/04_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3kXGCVmE7Cw",
        "colab_type": "text"
      },
      "source": [
        "**Load Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAtIeUiVE7tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp39ORVto4U4",
        "colab_type": "text"
      },
      "source": [
        "**setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWi2w3N7XPIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What GPU do we have ?\n",
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUK5O_dm77il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rExthsB47ZDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies\n",
        "! pip install pytorch-lightning wandb --quiet\n",
        "! pip install git+https://github.com/albumentations-team/albumentations --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRWaGYaaFNZf",
        "colab_type": "text"
      },
      "source": [
        "**Before running this cell make sure that the data is present in `GoogleDrive` at `Data/oxford-iiit-pet.tgz` .  \n",
        "The Data can be downloaded at [here](https://www.robots.ox.ac.uk/~vgg/data/pets/).  \n",
        "Running this cell will extract the data and save it to the `/content/oxford-iiit-pet` .**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f9AQLYk7rb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip the data assuming the `The Oxford-IIIT Pet Dataset` is present as /content/drive/My\\ Drive/Data/oxford-iiit-pet.tgz\n",
        "# to download the dataset go to this link:\n",
        "# https://www.robots.ox.ac.uk/~vgg/data/pets/\n",
        "!tar xf /content/gdrive/My\\ Drive/Data/oxford-iiit-pet.tgz -C /content/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXbdqBISGCA2",
        "colab_type": "text"
      },
      "source": [
        "**Clone the retinanet repo:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKlLraERBfBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the RetinaNet Repo:\n",
        "! git clone https://github.com/benihime91/pytorch_retinanet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNYPN2pXGHUa",
        "colab_type": "text"
      },
      "source": [
        "**Instantiate wandb :**  \n",
        "**If using `wandb` to track logs uncomment the cell and run it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIbuLRdNMkwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use wandb to track experiments : Comment this if not using wandb logger\n",
        "! wanbd login # a74f67fd5fae293e301ea8b6710ee0241f595a63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huCcIyL1Yq78",
        "colab_type": "text"
      },
      "source": [
        "**required imports:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxe4SxVhsbFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "from typing import *\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPftv4D-8IfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# PyTorch Imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Lightning import\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import (EarlyStopping, ModelCheckpoint, LearningRateLogger,)\n",
        "\n",
        "# Import some usefull utilities from the RetinaNet Repo:\n",
        "from pytorch_retinanet.src.models import Retinanet\n",
        "from pytorch_retinanet.src.utils.eval_utils import CocoEvaluator\n",
        "from pytorch_retinanet.src.utils.eval_utils import get_coco_api_from_dataset\n",
        "from pytorch_retinanet.src.utils.general_utils import collate_fn, xml_to_csv\n",
        "from pytorch_retinanet import DetectionDataset, Visualizer\n",
        "\n",
        "pl.seed_everything(42) # change this seed number to get different results\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H91ihUM_o2Am",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess the data:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFX-GP1A-CvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annot_dir = '/content/oxford-iiit-pet/annotations/xmls' # folder where the annotations are stored\n",
        "img_dir = '/content/oxford-iiit-pet/images' # folder where the training Images are stored\n",
        "\n",
        "# Create pandas DataFrame from the xmls\n",
        "df = xml_to_csv(annot_dir)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKVkxucm9Z_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regex to extract the class names from the filenames of the csv file\n",
        "pat = r\"/([^/]+)_\\d+.jpg$\"\n",
        "pat = re.compile(pat)\n",
        "\n",
        "\n",
        "def get_classes(df : pd.DataFrame) -> pd.DataFrame:\n",
        "    \"creates labels for the Images from given filenames\"\n",
        "    # Extract the label\n",
        "    df[\"class\"] = [pat.search(fname).group(1).lower() for fname in df.filename]\n",
        "    return df\n",
        "\n",
        "\n",
        "def preprare_data(img_dir: str, data: Union[str, pd.DataFrame]) -> Union[pd.DataFrame, LabelEncoder]:\n",
        "    \"preprocess the given data and returns a pandas dataframe\"\n",
        "    if isinstance(data, str):\n",
        "        df = pd.read_csv(data)\n",
        "    else:\n",
        "        df = data\n",
        "    # modify filename to point to the image path\n",
        "    df[\"filename\"] = [os.path.join(img_dir, idx) for idx in df.filename.values]\n",
        "    # get labels from the filename\n",
        "    df = get_classes(df)\n",
        "    # encode the labels: convert labels to integers\n",
        "    le = LabelEncoder()\n",
        "    int_cls = le.fit(df[\"class\"].unique())\n",
        "    df[\"labels\"] = le.transform(df[\"class\"])\n",
        "    return df, le\n",
        "\n",
        "\n",
        "def create_label_dict(dataframe: pd.DataFrame, encoder: LabelEncoder) -> Dict[int, str]:\n",
        "    \"Creates a label dictionary from the given dataframe `labels`\"\n",
        "    names = list(dataframe.labels.unique())\n",
        "    names.sort()\n",
        "    # Create the label dictionary\n",
        "    label_dict = {idx: clas for idx, clas in zip(\n",
        "        names, list(encoder.inverse_transform(names)))}\n",
        "    return label_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoiOh1Ha9pYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df , le = preprare_data(img_dir, df)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI-dUUuq9yeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab the label dictionary\n",
        "label_dict = create_label_dict(df, le)\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlwxinnxNmJz",
        "colab_type": "text"
      },
      "source": [
        "**utility function to display image with bounding boxes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N_XYCG-91Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the visualizer\n",
        "viz = Visualizer(class_names=label_dict)\n",
        "\n",
        "# Function to display a random Image from the dataset\n",
        "def display_random_image(dataframe: pd.DataFrame) -> None:\n",
        "    \"displays a radom Image from given dataframe\"\n",
        "    n = np.random.randint(0, len(dataframe))\n",
        "    fname = df[\"filename\"][n]\n",
        "    boxes = df.loc[df[\"filename\"] == fname][[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "    labels = df.loc[df[\"filename\"] == fname][\"labels\"].values\n",
        "    viz.draw_bboxes(fname, boxes=boxes, classes=labels, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzATrShPNfh3",
        "colab_type": "text"
      },
      "source": [
        "**Display image from the data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMLYlKTBCCxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display some random Images from the Dataset for sanity check\n",
        "display_random_image(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7HBWfqlCGd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to split a given DataFrame\n",
        "def create_splits(df: pd.DataFrame, split_sz: float = 0.3) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"Split given DataFrame into `split_sz`\"\n",
        "    \n",
        "    # Grab the Unique Image Idxs from the Filename\n",
        "    unique_ids = list(df.filename.unique())\n",
        "    # Split the Unique Image Idxs into Train & valid Datasets\n",
        "    train_ids, val_ids = train_test_split(\n",
        "        unique_ids, shuffle=True, random_state=42, test_size=split_sz\n",
        "    )\n",
        "\n",
        "    # Create Splits on the DataFrame\n",
        "    df[\"split\"] = 0\n",
        "\n",
        "    for i, idx in enumerate(df.filename.values):\n",
        "        if idx in set(train_ids):\n",
        "            df[\"split\"][i] = \"train\"\n",
        "        elif idx in set(val_ids):\n",
        "            df[\"split\"][i] = \"val\"\n",
        "\n",
        "    # Split the DataFrame into Train and Valid DataFrames\n",
        "    df_trn, df_val = df.loc[df[\"split\"] == \"train\"], df.loc[df[\"split\"] == \"val\"]\n",
        "\n",
        "    df_trn, df_val = df_trn.reset_index(drop=True), df_val.reset_index(drop=True)\n",
        "\n",
        "    # drop the extra redundent column\n",
        "    df_trn.drop(columns=[\"split\"], inplace=True)\n",
        "    df_val.drop(columns=[\"split\"], inplace=True)\n",
        "\n",
        "    return df_trn, df_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-lF4W09N6XP",
        "colab_type": "text"
      },
      "source": [
        "**Create spilts in the DataFrame to get `train`, `validation` & `test` sets**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8TaetteCvIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create train and validation splits from the dataframe\n",
        "df_trn, df_val = create_splits(df, split_sz=0.3)\n",
        "df_val, df_test = create_splits(df_val, split_sz=0.5)\n",
        "\n",
        "print('Num examples in train dataset :', len(df_trn.filename.unique()))\n",
        "print('Num examples in valid dataset :', len(df_val.filename.unique()))\n",
        "print('Num examples in test dataset :', len(df_test.filename.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tuui63VJNdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Peek at the train dataset for sanity check\n",
        "df_trn.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otymrAkDCyct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Peek at the validation dataset for sanity check\n",
        "df_val.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkkP4AjUZAOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjWpg_JkYRAn",
        "colab_type": "text"
      },
      "source": [
        "**sanity check**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKcWB1tlC2Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display random image from the train, valid \n",
        "# & test datasets for sanity check\n",
        "display_random_image(dataframe=df_trn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duBHyTmJYUUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_random_image(dataframe=df_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVsvebrLYVko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_random_image(dataframe=df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy40Yfhq-J0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the dataframes\n",
        "df_trn.to_csv('train.csv', index=False)\n",
        "df_test.to_csv('test.csv', index=False)\n",
        "df_val.to_csv('val.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "474cBYh1OFgO",
        "colab_type": "text"
      },
      "source": [
        "**Instantiate image transformations:**\n",
        "\n",
        "We use `albumentations` for image transformations. Check [albumentations docs](https://albumentations.ai/docs/examples/example_bboxes/) for API reference & list of transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL2VQ6ihDYgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfms() -> Dict[str, A.Compose]:\n",
        "    \"Returns a dictionary contatining transformations for train & valid/test datasets\"\n",
        "    \n",
        "    # train transformations : [Modify this to add Transformations to train dataset] \n",
        "    trn_tfms = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ToGray(p=0.2),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.CLAHE(p=0.5),\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),\n",
        "    ]\n",
        "\n",
        "    # validation transformations : [Transformations to the validation dataset]\n",
        "    val_tfms = [\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),\n",
        "    ]\n",
        "\n",
        "    # test transformations : [Transformations to the test dataset]\n",
        "    tst_tfms = [\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),                \n",
        "    ]\n",
        "\n",
        "    # transforms dictionary :\n",
        "    transforms = {\n",
        "        \"train\": A.Compose(trn_tfms, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),),\n",
        "        \"valid\": A.Compose(val_tfms, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),),\n",
        "        \"test\" : A.Compose(tst_tfms, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),),\n",
        "    }\n",
        "    \n",
        "    return transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n98cLKv0Pt-z",
        "colab_type": "text"
      },
      "source": [
        "**Create `pl.LightningModule` instance :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcIdKqxOEvem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create pl.LightningModule instance\n",
        "\n",
        "# ========\n",
        "# INFO :\n",
        "# ========\n",
        "# The hparams config file should contain the following :\n",
        "# ========\n",
        "# 1. optimizer : torch.optim.Optimizer -> Optimizer for the model\n",
        "# 2. scheduler : Union[torch.optim.lr_scheduler, None] -> Scheduler for the Optimizer\n",
        "\n",
        "# 3. trn_df    : pandas.DataFrame -> train dataframe\n",
        "# 4. trn_bs    : int -> train batch_size\n",
        "\n",
        "# 5. val_df    : pandas.DataFrame -> validation dataframe\n",
        "# 6. val_bs    : int -> validation batch_size\n",
        "\n",
        "# 7. test_df   :  pandas.DataFrame -> test dataframe\n",
        "# 8. test_bs   : int -> test batch_size\n",
        "\n",
        "# 9. iou_types : List -> for coco evaluation set it to [\"bbox\"].\n",
        "\n",
        "class DetectionModel(pl.LightningModule):\n",
        "    def __init__(self, model: nn.Module, hparams: argparse.Namespace) -> None:\n",
        "        super(DetectionModel, self).__init__()\n",
        "        self.model = model\n",
        "        self.hparams = hparams\n",
        "\n",
        "    @property\n",
        "    def num_batches(self) -> List:\n",
        "        \"returns a list containing the number of batches in train, val & test dataloaders\"\n",
        "        return [len(self.train_dataloader()), len(self.val_dataloader()), len(self.test_dataloader())]\n",
        "\n",
        "    ##################################################################\n",
        "    ############## Configure Optimizer & Schedulers ##################\n",
        "    ##################################################################\n",
        "    def configure_optimizers(self, *args, **kwargs):\n",
        "        \"instatiate optimizer & scheduler(s)\" \n",
        "        # optimizer\n",
        "        optimizer = self.hparams.optimizer\n",
        "        # scheduler\n",
        "        scheduler = self.hparams.scheduler\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            return [optimizer], [scheduler]\n",
        "        else:\n",
        "            return [optimizer]\n",
        "\n",
        "    ##################################################################\n",
        "    ############# Forward Pass of the Model ##########################\n",
        "    ##################################################################\n",
        "    def forward(self, xb, *args, **kwargs):\n",
        "        \"forward step\"\n",
        "        return self.model(xb)\n",
        "\n",
        "    ##################################################################\n",
        "    ########################## preprare data #########################\n",
        "    ##################################################################\n",
        "    def setup(self, stage=None):\n",
        "        # Instantiate Transforms:\n",
        "        self.tfms    = get_tfms()\n",
        "        # Load in the DataFrames\n",
        "        self.trn_df  = pd.read_csv(self.hparams.trn_df) # train dataframe\n",
        "        self.val_df  = pd.read_csv(self.hparams.val_df) # valid dataframe\n",
        "        self.test_df = pd.read_csv(self.hparams.test_df) # test dataframe\n",
        "\n",
        "    ##################################################################\n",
        "    ########################### Trainining ###########################\n",
        "    ##################################################################\n",
        "    def train_dataloader(self, *args, **kwargs):\n",
        "        \"instantiate train dataloader\" \n",
        "        # instantiate the trian dataset\n",
        "        train_ds = DetectionDataset(self.trn_df, self.tfms['train'])\n",
        "        # load in the dataloader\n",
        "        trn_dl = DataLoader(\n",
        "            train_ds, batch_size=self.hparams.trn_bs, shuffle=True, collate_fn=collate_fn, pin_memory=True,\n",
        "            )\n",
        "        \n",
        "        return trn_dl\n",
        "\n",
        "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        \"one training step\"\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        loss_dict = self.model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        return {\"loss\": losses, \"log\": loss_dict, \"progress_bar\": loss_dict}\n",
        "\n",
        "    ##################################################################\n",
        "    ###################### Validation ################################\n",
        "    ##################################################################\n",
        "    def val_dataloader(self, *args, **kwargs):\n",
        "        \"instatiate validation dataloader\"\n",
        "        # instantiate the validaiton dataset\n",
        "        val_ds = DetectionDataset(self.val_df, self.tfms['valid'])\n",
        "        # instantiate dataloader\n",
        "        loader = DataLoader(val_ds, batch_size=self.hparams.val_bs, shuffle=False, collate_fn=collate_fn,)\n",
        "        # instantiate coco_api to track metrics\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.coco_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        \"one validation step\"\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.coco_evaluator.update(res)\n",
        "        return {}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.coco_evaluator.accumulate()\n",
        "        self.coco_evaluator.summarize()\n",
        "        metric = self.coco_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"valid_mAP\": metric}\n",
        "        return {\"valid_mAP\": metric, \"log\": logs, \"progress_bar\": logs,}\n",
        "    \n",
        "    ##################################################################\n",
        "    ######################## Test ####################################\n",
        "    ##################################################################\n",
        "    def test_dataloader(self, *args, **kwargs):\n",
        "        \"instatiate validation dataloader\"\n",
        "        # instantiate train dataset\n",
        "        test_ds = DetectionDataset(self.test_df, self.tfms['test'])\n",
        "        # instantiate dataloader\n",
        "        loader = DataLoader(test_ds, batch_size=self.hparams.test_bs, shuffle=False, collate_fn=collate_fn,)\n",
        "        # instantiate coco_api to track metrics\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.test_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def test_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        \"one test step\"\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.test_evaluator.update(res)\n",
        "        return {}\n",
        "    \n",
        "    def test_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.test_evaluator.accumulate()\n",
        "        self.test_evaluator.summarize()\n",
        "        metric = self.test_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"test_mAP\": metric}\n",
        "        return {\"test_mAP\": metric, \"log\": logs, \"progress_bar\": logs,}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LWyLxqLTMlB",
        "colab_type": "text"
      },
      "source": [
        "**Specify Configs: :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RX6vOpftZoY",
        "colab_type": "text"
      },
      "source": [
        "**Configs for `DetectionModel` :**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfjznYS7tjq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================= #\n",
        "# Specify Patametrs for the DetectionModel:\n",
        "# ============================================= #\n",
        "\n",
        "# load in the RetinaNet model\n",
        "NUM_CLASSES = 37  # Oxford-IIIT Pets Dataset has 37 classes\n",
        "BACKBONE = 'resnet18' # backbone for RetinaNet Model\n",
        "model = Retinanet(num_classes=NUM_CLASSES, backbone_kind=BACKBONE)\n",
        "\n",
        "# instantiate optimizer\n",
        "LR = 1e-03 # learning rate for Optimizer\n",
        "MOMENTUM = 0.9 # Momentum for the Optimizer\n",
        "WEIGHT_DECAY = 0.0001 # Weight Decay for Optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = SGD(params, LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM)\n",
        "\n",
        "# Instantiate scheduler\n",
        "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "# convert scheduler to lightning format\n",
        "INTERVAL = \"step\" # scheduler interval wether after each 'step' for each 'epoch'\n",
        "scheduler = {\"scheduler\": scheduler, \"interval\": INTERVAL , \"frequency\": 1,}\n",
        "\n",
        "# Train dataset Parametrs:\n",
        "trn_df = '/content/train.csv' # path 2 dataframe\n",
        "trn_bs = 32 # batch_size\n",
        "\n",
        "# Valid dataset parametrs:\n",
        "val_df = '/content/val.csv' # path 2 dataframe\n",
        "val_bs = 32 # batch_size\n",
        "\n",
        "# Test dataset parametrs:\n",
        "test_df = '/content/test.csv' # path 2 dataframe\n",
        "test_bs = 32 # batch_size\n",
        "\n",
        "# set iou types:\n",
        "iou_types = ['bbox']\n",
        "\n",
        "\n",
        "# Create arguments:\n",
        "hparams = {\n",
        "    'optimizer': optimizer,\n",
        "    'scheduler': scheduler,\n",
        "    'trn_df' : trn_df,\n",
        "    'trn_bs': trn_bs,\n",
        "    'val_df' : val_df,\n",
        "    'val_bs': val_bs,\n",
        "    'test_df' : test_df,\n",
        "    'test_bs': test_bs,\n",
        "    'iou_types': iou_types,\n",
        "}\n",
        "\n",
        "# Convert dictionary to args\n",
        "hparams= argparse.Namespace(**hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ4eCeb1ywPK",
        "colab_type": "text"
      },
      "source": [
        "**Configs for `LightningTrainer`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tQWfupJzZOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create configs for lighntning trainer\n",
        "\n",
        "# Wandb logger: assuming wandb is set-up [Optional]\n",
        "wb_name = f\"resnet34-||-{time.strftime('%d-%m-||-%I.%M.%S%-p')}\" # change the run name here\n",
        "wb_p = \"retinanet-oxford-pets\" # change the project name here\n",
        "wb_logger = WandbLogger(name=wb_name, project=wb_p, anonymous=\"allow\",)\n",
        "\n",
        "# learning_rate logger:\n",
        "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
        "\n",
        "# set callbacks & loggers:\n",
        "logger=[wb_logger]\n",
        "callbacks=[lr_logger]\n",
        "\n",
        "# checkpoint callback\n",
        "fname = \"/content/drive/My Drive/pets_resnet34_checkpoints\" \n",
        "os.makedirs(fname, exist_ok=True)\n",
        "checkpoint_callback = ModelCheckpoint(fname, mode=\"max\", monitor=\"valid_mAP\", save_top_k=4,)\n",
        "\n",
        "# early stopping callback\n",
        "early_stop_callback = EarlyStopping(mode=\"max\", monitor=\"valid_mAP\", patience=5,)\n",
        "\n",
        "check_val_every_n_epoch=10 # Validaiton Check Interval\n",
        "gpus = 1  # gpus to use\n",
        "precision = 16 # precision\n",
        "max_epochs = 100 # Total number of Epochs\n",
        "\n",
        "# Cconvert trainer flags into a dictionary\n",
        "trainer_config = {\n",
        "    'num_sanity_val_steps' : 0,\n",
        "    'benchmark': True,\n",
        "    'logger': logger,\n",
        "    'callbacks': callbacks,\n",
        "    'checkpoint_callback': checkpoint_callback,\n",
        "    'early_stop_callback' : early_stop_callback,\n",
        "    'gpus': gpus,\n",
        "    'precision': precision,\n",
        "    'max_epochs': max_epochs,\n",
        "    'check_val_every_n_epoch': check_val_every_n_epoch,\n",
        "}\n",
        "\n",
        "trainer_config = argparse.Namespace(**trainer_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62lxSQaKmuXs",
        "colab_type": "text"
      },
      "source": [
        "**Grab the model & the trainer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GX7IjCeF9xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate lightning model\n",
        "retinanet = DetectionModel(model, hparams)\n",
        "# instantiate lightning trainer\n",
        "trainer = pl.Trainer.from_argparse_args(trainer_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDTQBpRhWUJ8",
        "colab_type": "text"
      },
      "source": [
        "**Train model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmwRvRK0GLXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.fit(retinanet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2RsQnnWV38",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ado3NN6GzVsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model on the Test DataLoader\n",
        "# NB: Best weights are automatically loaded\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eZASMzEqIiW",
        "colab_type": "text"
      },
      "source": [
        "**save trained weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVBbx_EqqL9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = '/content/drive/My Drive/resnet18-pets-ver0.0.1.pth'\n",
        "torch.save(retinanet.model.state_dict(), fname, _use_new_zipfile_serialization=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIjTsmOovxo",
        "colab_type": "text"
      },
      "source": [
        "**Inference**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpzx3tTFXAAS",
        "colab_type": "text"
      },
      "source": [
        "**Load in a `torch` model to do inference:**  \n",
        "\n",
        "**Model weights can be loaded in 2 ways either load the weights trained above in that case set fname to be the `path` to where the `state_dict` is saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0B34LISdMTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate Torch Model for Inference\n",
        "m = Retinanet(num_classes=37, backbone_kind='resnet18')\n",
        "\n",
        "# Load in the pretrained model weights from weights file\n",
        "fname = None\n",
        "m.load_state_dict(torch.load(fname))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvNGuw82IXGY",
        "colab_type": "text"
      },
      "source": [
        "**To load model weights from already trained weights that are available [here](https://github.com/benihime91/retinanet_pet_detector/releases).**  \n",
        "\n",
        "**Uncomment the cell given below.**  \n",
        "**Copy the `url` of the weights file and set the url to be the one copied.**\n",
        "**If using `GPU` set device to be `gpu` else set it to be `cpu`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbsHl_9-I40-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# url = None\n",
        "# device = 'gpu'\n",
        "\n",
        "# # load model state_dict from url\n",
        "# state_dict = torch.hub.load_state_dict_from_url(url, map_location=device)\n",
        "# m.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjtcQAvbXNi9",
        "colab_type": "text"
      },
      "source": [
        "**import & helper functions for inference:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOM64wy_dqT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from torchvision.ops.boxes import batched_nms\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_tfms = A.Compose([A.ToFloat(max_value=255.0, always_apply=True), ToTensorV2(always_apply=True),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is1_vzXkeesg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def get_preds(\n",
        "    model: Union[nn.Module, pl.LightningModule],\n",
        "    path: str,\n",
        "    threshold: float,\n",
        "    iou_threshold: float,\n",
        "    device: torch.device,\n",
        ") -> Tuple[List, List, List]:\n",
        "    \"Get predictions on image\"\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    # Load the imag\n",
        "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    # Process the image\n",
        "    img = test_tfms(image=img)[\"image\"]\n",
        "    img = img.to(device)\n",
        "    # Generate predictions\n",
        "    model.eval()\n",
        "    pred = model([img])\n",
        "\n",
        "    # Gather the bbox, scores & labels from the preds\n",
        "    pred_boxes = pred[0][\"boxes\"]  # Bounding boxes\n",
        "    pred_class = pred[0][\"labels\"]  # predicted class labels\n",
        "    pred_score = pred[0][\"scores\"]  # predicted scores\n",
        "    # Get list of index with score greater than threshold.\n",
        "    mask = pred_score > threshold\n",
        "    # Filter predictions\n",
        "    boxes = pred_boxes[mask]\n",
        "    clas = pred_class[mask]\n",
        "    scores = pred_score[mask]\n",
        "\n",
        "    # do NMS\n",
        "    keep_idxs = batched_nms(boxes, scores, clas, iou_threshold)\n",
        "    boxes = list(boxes[keep_idxs].cpu().numpy())\n",
        "    clas = list(clas[keep_idxs].cpu().numpy())\n",
        "    scores = list(scores[keep_idxs].cpu().numpy())\n",
        "    return boxes, clas, scores\n",
        "\n",
        "\n",
        "def object_detection_api(\n",
        "    model: Union[nn.Module, pl.LightningModule],\n",
        "    device: torch.device,\n",
        "    img_path: str = None,\n",
        "    score_threshold: float = 0.5,\n",
        "    iou_threshold: float = 0.2,\n",
        ") -> None:\n",
        "    \"Draw bbox predictions on given image at img_pth\"\n",
        "    if img_path is None:\n",
        "        uploaded = files.upload()\n",
        "        img_path = list(uploaded.keys())[0]\n",
        "    print(\"[INFO] Generating predictions ....\")\n",
        "    bb, cls, sc = get_preds(model, img_path, score_threshold, iou_threshold, device,)\n",
        "    print(\"[INFO] Creating bbox on the image .... \")\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "    viz.draw_bboxes(img, boxes=bb, classes=cls, scores=sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvxheUJFXonZ",
        "colab_type": "text"
      },
      "source": [
        "**inference on test images:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Bjihgpe07e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 10 # index of the test_image\n",
        "object_detection_api(m, device=device, score_threshold=0.7, iou_threshold=0.2, img_path=df_test[\"filename\"][idx],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5d_8kNXs-q",
        "colab_type": "text"
      },
      "source": [
        "**inference on user given images:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQnBdkC8v0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference on User Images\n",
        "object_detection_api(m, device=device, score_threshold=0.7, iou_threshold=0.2,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2cgFjk6-awc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}