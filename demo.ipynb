{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bR2lmX5zBzpH",
        "ryy-KrEWDCcp",
        "1o9RywdIDfL3",
        "iHaI90RWG8Yu",
        "6DVhgFiRIbLM",
        "gyuBTLBwJlRy"
      ],
      "mount_file_id": "1lcSuI3Bs8DLIjEFQXg_nRJiEEmonR0jL",
      "authorship_tag": "ABX9TyPlyq+yVI6xpyydrO22tAeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/retinanet_pet_detector/blob/master/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuoMBNZA_fZO"
      },
      "source": [
        "<div align=\"center\">\n",
        "<h1><b> Pet Face Detector üëÅ üê∂ üê± </b></h1>\n",
        "<p align=\"center\"><img src=\"https://github.com/benihime91/retinanet_pet_detector/blob/master/images/res_3.png?raw=true\" height=\"300\"> </p>  \n",
        "<b> Using a RetinaNet to detect faces of common breeds of Pets </b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSu3MnNhBxdC"
      },
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_YW1B_RBpP8"
      },
      "source": [
        "# what GPU do we have ?\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2lmX5zBzpH"
      },
      "source": [
        "## **Setup Google-Colab:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON65LTJRB5uW"
      },
      "source": [
        "# install dependencies\n",
        "!pip install --upgrade pytorch-lightning omegaconf --quiet\n",
        "!pip install git+https://github.com/albumentations-team/albumentations --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8kZl__wB760"
      },
      "source": [
        "# Uncommment & run this cell to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh267ZgEDFml"
      },
      "source": [
        "# clone the github repo:\n",
        "!git clone --recurse-submodules https://github.com/benihime91/retinanet_pet_detector.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXs6GDW9C65B"
      },
      "source": [
        "**Untar the data from Google Drive and save it to VM memory :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNbiZO5bCBGH"
      },
      "source": [
        "- The cell below unzips the data assuming the `The Oxford-IIIT Pet Dataset` is present in `/content/drive/My Drive/Data/oxford-iiit-pet.tgz.`\n",
        "\n",
        "- If data is not downloaded download the data from [here](https://www.robots.ox.ac.uk/~vgg/data/pets) and save in it in Google Drive under `/Data/oxford-iiit-pet.tgz`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UDzTLN9B-de"
      },
      "source": [
        "# unpacks the data\n",
        "!tar xf /content/drive/My\\ Drive/Data/oxford-iiit-pet.tgz -C /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryy-KrEWDCcp"
      },
      "source": [
        "## **Import dependencies:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuv52UCjDNG1"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "os.chdir(\"/content/retinanet_pet_detector\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgZ77OBFDPN2"
      },
      "source": [
        "# Standard Imports\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf, DictConfig\n",
        "import pandas as pd\n",
        "import argparse\n",
        "from PIL import Image\n",
        "\n",
        "from references import Visualizer\n",
        "from references.utils import get_label_dict\n",
        "from train import main\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\",None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o9RywdIDfL3"
      },
      "source": [
        "## **Preprare Data:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKSK-w85Dmr9"
      },
      "source": [
        "Before training we need to convert the data into a format that is compatible with the `training pipeline.` We will use `references/data_utils.py` to convert all the xml annotation files into a csv that stores all the annotations and path to the Images.\n",
        "\n",
        "The resutant csv file will be saved as `/{ouptut_dir}/data-full.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7evHpgnD8Mu"
      },
      "source": [
        "# Convert xml files to a csv file\n",
        "!python prep_data.py \\\n",
        "    --action create \\\n",
        "    --img_dir \"/content/oxford-iiit-pet/images\" \\\n",
        "    --annot_dir \"/content/oxford-iiit-pet/annotations/xmls\" \\\n",
        "    --labels \"/content/retinanet_pet_detector/data/labels.names\" \\\n",
        "    --output_dir \"/content/retinanet_pet_detector/data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pXHIpdLEgHj"
      },
      "source": [
        "This is what our data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMU4OrEmEMBy"
      },
      "source": [
        "df = pd.read_csv(\"/content/retinanet_pet_detector/data/data-full.csv\")\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrrihtQij7tk"
      },
      "source": [
        "# sanity-check\n",
        "Image.open(df.filename[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ge3Q62dEPeQ"
      },
      "source": [
        "We will again the run the script used above but this time we will run this script to create `training`, `validation` & `test` sets from the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmoltQ-qEdjR"
      },
      "source": [
        "# Create train, validaiton and test splits in the data\n",
        "!python prep_data.py \\\n",
        "    --action split \\\n",
        "    --csv \"/content/retinanet_pet_detector/data/data-full.csv\"\\\n",
        "    --valid_size 0.3 \\\n",
        "    --test_size 0.5 \\\n",
        "    --output_dir \"/content/retinanet_pet_detector/data/\" \\\n",
        "    --seed 123"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QLMvn-9Exdr"
      },
      "source": [
        "We can see that now we have 3 extra files train.csv, valid.csv & test.csv. This files correspond to the `train`,`validation` & `test` datasets respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fApEumuEkl2"
      },
      "source": [
        "! ls \"/content/retinanet_pet_detector/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNj5LoXKF7-L"
      },
      "source": [
        "# Read in the train and test dataframes\n",
        "trn_df = pd.read_csv(\"/content/retinanet_pet_detector/data/train.csv\")\n",
        "tst_df = pd.read_csv(\"/content/retinanet_pet_detector/data/test.csv\")\n",
        "val_df = pd.read_csv(\"/content/retinanet_pet_detector/data/valid.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTBWvNR4GHdu"
      },
      "source": [
        "print(\"Num training examples :\", len(trn_df))\n",
        "trn_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpexZRBEGNyK"
      },
      "source": [
        "print(\"Num testing examples :\", len(tst_df))\n",
        "tst_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run6FUqVkGH9"
      },
      "source": [
        "print(\"Num validation examples :\", len(val_df))\n",
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhG9J-3SGeh1"
      },
      "source": [
        "**View some images from the datasets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtnH9Rl5Gk0K"
      },
      "source": [
        "# Read in the Labes dictionary \n",
        "# and initializer the visualizer to view images with bboxes\n",
        "label_dict = get_label_dict(\"/content/retinanet_pet_detector/data/labels.names\")\n",
        "vis = Visualizer(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XniyvbujueKz"
      },
      "source": [
        "# These are the label\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOBYiTcmGwy2"
      },
      "source": [
        "np.random.seed(123)\n",
        "\n",
        "def display_random_image(data):\n",
        "    \"\"\"\n",
        "    Fn to display a random using the `Visualizer`\n",
        "    from the given pandas dataframe. The bounding boxes are also\n",
        "    drawn over the image.\n",
        "\n",
        "    Args:\n",
        "     data (`pd.dataframe`): A `pandas dataframe` where filename corresponds to \n",
        "                            the image path and bbox co-ordinates are stored in \n",
        "                            `[xmin,xmax,ymin,ymax]` & class_names (`int`) are \n",
        "                            stored in `[labels]`.\n",
        "    \"\"\"\n",
        "    idx = np.random.randint(0, len(df))\n",
        "    image_id = df.filename[idx]\n",
        "    locs = df.loc[df.filename == image_id]\n",
        "    boxes = locs[['xmin','ymin','xmax','ymax']].values\n",
        "    labels = locs['labels'].values\n",
        "    vis.draw_bboxes(image_id, boxes, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ_SDWOQG0Rw"
      },
      "source": [
        "# Display a random Image from the Train dataset\n",
        "display_random_image(data=trn_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DByIafeKG4Ma"
      },
      "source": [
        "# Display a random Image from the test dataset\n",
        "display_random_image(data=tst_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRr-9LvHkIfA"
      },
      "source": [
        "# Display a random Image from the validation dataset\n",
        "display_random_image(data=val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHaI90RWG8Yu"
      },
      "source": [
        "## **Modify Config file:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgfNdHPEBPLZ"
      },
      "source": [
        "**Setup paths:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mme3gRFHMPy"
      },
      "source": [
        "import time\n",
        "\n",
        "# load the config file\n",
        "config = OmegaConf.load(\"/content/retinanet_pet_detector/config/main.yaml\")\n",
        "\n",
        "# -------------------------------------------- #\n",
        "# Modify some config parameters:\n",
        "# -------------------------------------------- #\n",
        "fname = f\"/content/drive/My Drive/{time.strftime('[%m-%d]%H-%M-%S')}\"\n",
        "\n",
        "config.model.backbone_kind = \"resnet50\" \n",
        "config.hparams.train_csv = \"/content/retinanet_pet_detector/data/train.csv\"\n",
        "config.hparams.valid_csv = \"/content/retinanet_pet_detector/data/valid.csv\"\n",
        "config.hparams.test_csv  = \"/content/retinanet_pet_detector/data/test.csv\"\n",
        "config.trainer.model_checkpoint.params.filepath = fname\n",
        "config.trainer.logger.params.save_dir = \"/content/logs/\"\n",
        "config.trainer.early_stopping.params.patience = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDPLbKXeBUyA"
      },
      "source": [
        "**update config file for train:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qaz-plcBUM3"
      },
      "source": [
        "# Save the modified config file\n",
        "OmegaConf.save(config=config, f=\"/content/retinanet_pet_detector/config/main.yaml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlv5XRMzIU0n"
      },
      "source": [
        "# Load and view the modified config file\n",
        "config = OmegaConf.load(\"/content/retinanet_pet_detector/config/main.yaml\")\n",
        "# let's take a look at out config file\n",
        "print(OmegaConf.to_yaml(config))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DVhgFiRIbLM"
      },
      "source": [
        "## **Train, Validation & Test :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjZ-pijQImF8"
      },
      "source": [
        "In colab use the main function to train otherwise Lightning progress bar goes mad, this issue is highlighted [here]( https://github.com/PyTorchLightning/pytorch-lightning/issues/721). \n",
        "\n",
        "The `main` function accepts `argparse` arguments so we will first define a `Dictionary` with the args and convert it to `argparse.Namespace` instance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEMnSUQB-nuT"
      },
      "source": [
        "**Config for train:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOY5rNLNIhq4"
      },
      "source": [
        "# Creat argument dictionary\n",
        "d = {\"config\": \"/content/retinanet_pet_detector/config/main.yaml\", \"verbose\": 0}\n",
        "# Creat argument dictionary\n",
        "args = DictConfig(d)\n",
        "print(args.pretty())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a74fbFHP7KX"
      },
      "source": [
        "### **Start Loop for train, validation and test :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoRYEGzNJC53"
      },
      "source": [
        "# run the main function\n",
        "# set a seed number to ensure results are reproducible\n",
        "main(args, seed=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK3uEyW74L3q"
      },
      "source": [
        "%tensorboard --logdir \"/content/logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyuBTLBwJlRy"
      },
      "source": [
        "## **Inference with saved weights:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGT0olSXJqtp"
      },
      "source": [
        "To do inference we need to modify or create a config file for inference. The config file for inference should contain the following:\n",
        "- `model_backbone` (`str`) : resnet backbone used for the retinanet model.\n",
        "- `url` (`str`) : url or the path to where weights are saved.\n",
        "- `num_classes` (`int`) : total number of unique classes.\n",
        "\n",
        "We will save this `config` file at : `/content/retinanet_pet_detector/config/resnet50.yaml`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPrmJ1ll0Tgt"
      },
      "source": [
        "### **Instantiate config for inference:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eT3wOTJJvEw"
      },
      "source": [
        "# we used a resnet34 model so,\n",
        "# we will set the backbone to be `renet34`\n",
        "backbone = \"resnet50\"\n",
        "# path to where model weights are saved\n",
        "url = \"/content/drive/My Drive/pets/weights.pth\"\n",
        "# total number of classes\n",
        "num_classes = 37\n",
        "\n",
        "d = {\"model_backbone\": backbone, \"url\": url, \"num_classes\": num_classes}\n",
        "conf = DictConfig(d)\n",
        "\n",
        "# Save the config File\n",
        "fname = \"/content/retinanet_pet_detector/config/resnet50.yaml\"\n",
        "OmegaConf.save(config=conf, f=fname)\n",
        "\n",
        "# Print out the config File\n",
        "print(OmegaConf.to_yaml(conf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQZNJLJHOLIp"
      },
      "source": [
        "# path to the ocnfig file\n",
        "config = \"/content/retinanet_pet_detector/config/resnet50.yaml\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ML-TXeYMCOE"
      },
      "source": [
        "### **Run Inference:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLIfGdCFK7JF"
      },
      "source": [
        "!python inference.py \\\n",
        "    --config {config} \\\n",
        "    --image {tst_df.filename[100]} \\\n",
        "    --score_thres 0.7 \\\n",
        "    --iou_thres 0.4 \\\n",
        "    --save_dir \"/content/\" \\\n",
        "    --fname \"res_1.png\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ85Kk3RL7aN"
      },
      "source": [
        "Image.open(\"/content/res_1.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKpoAfoaLiTI"
      },
      "source": [
        "!python inference.py \\\n",
        "    --config {config} \\\n",
        "    --image {tst_df.filename[20]} \\\n",
        "    --score_thres 0.7 \\\n",
        "    --iou_thres 0.4 \\\n",
        "    --save_dir \"/content/\" \\\n",
        "    --fname \"res_2.png\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IexzvBKXLw83"
      },
      "source": [
        "Image.open(\"/content/res_2.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja5dowK-L2q3"
      },
      "source": [
        "**The following cells run inference on user uploaded image:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P9KgjtuM484"
      },
      "source": [
        "uploaded = files.upload()\n",
        "fname = list(uploaded.keys())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj0dt0UbM8Mb"
      },
      "source": [
        "!python inference.py \\\n",
        "    --config {config}\\\n",
        "    --image {fname} \\\n",
        "    --score_thres 0.7 \\\n",
        "    --iou_thres 0.4 \\\n",
        "    --save_dir \"/content/\" \\\n",
        "    --fname \"res_3.png\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZh_ChsCM_r-"
      },
      "source": [
        "Image.open(\"/content/res_3.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHqh-pW6N4Gz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}