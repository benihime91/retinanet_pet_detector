{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/retinanet_pet_detector/blob/master/nbs/04_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3kXGCVmE7Cw",
        "colab_type": "text"
      },
      "source": [
        "**Load Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAtIeUiVE7tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp39ORVto4U4",
        "colab_type": "text"
      },
      "source": [
        "**setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWi2w3N7XPIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What GPU do we have ?\n",
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUK5O_dm77il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rExthsB47ZDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies\n",
        "! pip install pytorch-lightning wandb --quiet\n",
        "! pip install git+https://github.com/albumentations-team/albumentations --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRWaGYaaFNZf",
        "colab_type": "text"
      },
      "source": [
        "**Before running this cell make sure that the data is present in `GoogleDrive` at `Data/oxford-iiit-pet.tgz` .  \n",
        "The Data can be downloaded at [here](https://www.robots.ox.ac.uk/~vgg/data/pets/).  \n",
        "Running this cell will extract the data and save it to the `/content/oxford-iiit-pet` .**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f9AQLYk7rb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip the data assuming the `The Oxford-IIIT Pet Dataset` is present as /content/drive/My\\ Drive/Data/oxford-iiit-pet.tgz\n",
        "# to download the dataset go to this link:\n",
        "# https://www.robots.ox.ac.uk/~vgg/data/pets/\n",
        "!tar xf /content/drive/My\\ Drive/Data/oxford-iiit-pet.tgz -C /content/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXbdqBISGCA2",
        "colab_type": "text"
      },
      "source": [
        "**Clone the retinanet repo:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKlLraERBfBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the RetinaNet Repo:\n",
        "! git clone https://github.com/benihime91/pytorch_retinanet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNYPN2pXGHUa",
        "colab_type": "text"
      },
      "source": [
        "**Instantiate wandb :**  \n",
        "**If using `wandb` to track logs uncomment the cell and run it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIbuLRdNMkwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use wandb to track experiments : Comment this if not using wandb logger\n",
        "# ! wanbd login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huCcIyL1Yq78",
        "colab_type": "text"
      },
      "source": [
        "**required imports:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPftv4D-8IfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import *\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "# from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    LearningRateLogger,\n",
        ")\n",
        "\n",
        "# Import some usefull utilities from the RetinaNet Repo\n",
        "from pytorch_retinanet.src.models import Retinanet\n",
        "from pytorch_retinanet.src.utils.eval_utils import CocoEvaluator\n",
        "from pytorch_retinanet.src.utils.eval_utils import get_coco_api_from_dataset\n",
        "from pytorch_retinanet.src.utils.general_utils import collate_fn, xml_to_csv\n",
        "from pytorch_retinanet import DetectionDataset, Visualizer\n",
        "\n",
        "pl.seed_everything(42) # change this seed number to get different results\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "warnings.filterwarnings('ignore')\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H91ihUM_o2Am",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess the data:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFX-GP1A-CvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annot_dir = '/content/oxford-iiit-pet/annotations/xmls' # folder where the annotations are stored\n",
        "img_dir = '/content/oxford-iiit-pet/images' # folder where the training Images are stored\n",
        "\n",
        "# Create pandas DataFrame from the xmls\n",
        "df = xml_to_csv(annot_dir)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKVkxucm9Z_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regex to extract the class names from the filenames of the csv file\n",
        "pat = r\"/([^/]+)_\\d+.jpg$\"\n",
        "pat = re.compile(pat)\n",
        "\n",
        "\n",
        "def get_classes(df=pd.DataFrame) -> pd.DataFrame:\n",
        "    \"creates labels for the Images from given filenames\"\n",
        "    # Extract the label\n",
        "    df[\"class\"] = [pat.search(fname).group(1).lower() for fname in df.filename]\n",
        "    return df\n",
        "\n",
        "\n",
        "def preprare_data(img_dir: str, data: Union[str, pd.DataFrame]) -> Union[pd.DataFrame, LabelEncoder]:\n",
        "    \"preprocess the given data and returns a pandas dataframe\"\n",
        "    if isinstance(data, str):\n",
        "        df = pd.read_csv(data)\n",
        "    else:\n",
        "        df = data\n",
        "    # modify filename to point to the image path\n",
        "    df[\"filename\"] = [os.path.join(img_dir, idx) for idx in df.filename.values]\n",
        "    # get labels from the filename\n",
        "    df = get_classes(df)\n",
        "    # encode the labels: convert labels to integers\n",
        "    le = LabelEncoder()\n",
        "    int_cls = le.fit(df[\"class\"].unique())\n",
        "    df[\"labels\"] = le.transform(df[\"class\"])\n",
        "    return df, le\n",
        "\n",
        "\n",
        "def create_label_dict(dataframe: pd.DataFrame, encoder: LabelEncoder) -> Dict[int, str]:\n",
        "    \"Creates a label dictionary from the given dataframe `labels`\"\n",
        "    names = list(dataframe.labels.unique())\n",
        "    names.sort()\n",
        "    # Create the label dictionary\n",
        "    label_dict = {idx: clas for idx, clas in zip(\n",
        "        names, list(encoder.inverse_transform(names)))}\n",
        "    return label_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoiOh1Ha9pYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df , le = preprare_data(img_dir, df)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI-dUUuq9yeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab the label dictionary\n",
        "label_dict = create_label_dict(df, le)\n",
        "label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlwxinnxNmJz",
        "colab_type": "text"
      },
      "source": [
        "**utility function to display image with bounding boxes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N_XYCG-91Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the visualizer\n",
        "viz = Visualizer(class_names=label_dict)\n",
        "\n",
        "# Function to display a random Image from the dataset\n",
        "def display_random_image(dataframe: pd.DataFrame) -> None:\n",
        "    \"displays a radom Image from given dataframe\"\n",
        "    n = np.random.randint(0, len(dataframe))\n",
        "    fname = df[\"filename\"][n]\n",
        "    boxes = df.loc[df[\"filename\"] == fname][[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "    labels = df.loc[df[\"filename\"] == fname][\"labels\"].values\n",
        "    viz.draw_bboxes(fname, boxes=boxes, classes=labels, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzATrShPNfh3",
        "colab_type": "text"
      },
      "source": [
        "**Display image from the data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMLYlKTBCCxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display some random Images from the Dataset for sanity check\n",
        "display_random_image(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7HBWfqlCGd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to split a given DataFrame\n",
        "def create_splits(df: pd.DataFrame, split_sz: float = 0.3) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"Split given DataFrame into `split_sz`\"\n",
        "    \n",
        "    # Grab the Unique Image Idxs from the Filename\n",
        "    unique_ids = list(df.filename.unique())\n",
        "    # Split the Unique Image Idxs into Train & valid Datasets\n",
        "    train_ids, val_ids = train_test_split(\n",
        "        unique_ids, shuffle=True, random_state=42, test_size=split_sz\n",
        "    )\n",
        "\n",
        "    # Create Splits on the DataFrame\n",
        "    df[\"split\"] = 0\n",
        "\n",
        "    for i, idx in enumerate(df.filename.values):\n",
        "        if idx in set(train_ids):\n",
        "            df[\"split\"][i] = \"train\"\n",
        "        elif idx in set(val_ids):\n",
        "            df[\"split\"][i] = \"val\"\n",
        "\n",
        "    # Split the DataFrame into Train and Valid DataFrames\n",
        "    df_trn, df_val = df.loc[df[\"split\"] ==\n",
        "                            \"train\"], df.loc[df[\"split\"] == \"val\"]\n",
        "    df_trn, df_val = df_trn.reset_index(\n",
        "        drop=True), df_val.reset_index(drop=True)\n",
        "\n",
        "    # drop the extra redundent column\n",
        "    df_trn.drop(columns=[\"split\"], inplace=True)\n",
        "    df_val.drop(columns=[\"split\"], inplace=True)\n",
        "\n",
        "    return df_trn, df_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-lF4W09N6XP",
        "colab_type": "text"
      },
      "source": [
        "**Create spilts in the DataFrame to get `train`, `validation` & `test` sets**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8TaetteCvIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create train and validation splits from the dataframe\n",
        "df_trn, df_val = create_splits(df, split_sz=0.3)\n",
        "df_val, df_test = create_splits(df_val, split_sz=0.5)\n",
        "\n",
        "print('Num examples in train dataset :', len(df_trn.filename.unique()))\n",
        "print('Num examples in train dataset :', len(df_val.filename.unique()))\n",
        "print('Num examples in train dataset :', len(df_test.filename.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tuui63VJNdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Peek at the train dataset for sanity check\n",
        "df_trn.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otymrAkDCyct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Peek at the validation dataset for sanity check\n",
        "df_val.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkkP4AjUZAOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjWpg_JkYRAn",
        "colab_type": "text"
      },
      "source": [
        "**sanity check**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKcWB1tlC2Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display random image from the train, valid \n",
        "# & test datasets for sanity check\n",
        "display_random_image(dataframe=df_trn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duBHyTmJYUUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_random_image(dataframe=df_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVsvebrLYVko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_random_image(dataframe=df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "474cBYh1OFgO",
        "colab_type": "text"
      },
      "source": [
        "**Instantiate image transformations:**\n",
        "\n",
        "We use `albumentations` for image transformations. Check [albumentations docs](https://albumentations.ai/docs/examples/example_bboxes/) for API reference & list of transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL2VQ6ihDYgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfms() -> Dict[str, A.Compose]:\n",
        "    \"Returns a dictionary contatining transformations for train & valid/test datasets\"\n",
        "    # train transformations : [Modify this to add Transformations to train dataset]\n",
        "    train_transformations = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ToGray(p=0.2),\n",
        "        A.RandomBrightnessContrast(),\n",
        "        A.CLAHE(),\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),\n",
        "    ]\n",
        "\n",
        "    # validation transformations : [Transformations to the validation & test dataset]\n",
        "    valid_transformations = [\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),\n",
        "    ]\n",
        "\n",
        "    # transforms dictionary :\n",
        "    transforms = {\n",
        "        \"train\": A.Compose(\n",
        "            train_transformations,\n",
        "            p=1.0,\n",
        "            bbox_params=A.BboxParams(\n",
        "                format=\"pascal_voc\", label_fields=[\"class_labels\"]\n",
        "            ),\n",
        "        ),\n",
        "        \"valid\": A.Compose(\n",
        "            valid_transformations,\n",
        "            p=1.0,\n",
        "            bbox_params=A.BboxParams(\n",
        "                format=\"pascal_voc\", label_fields=[\"class_labels\"]\n",
        "            ),\n",
        "        ),\n",
        "    }\n",
        "    return transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n98cLKv0Pt-z",
        "colab_type": "text"
      },
      "source": [
        "**Create `pl.LightningModule` instance :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcIdKqxOEvem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create pl.LightningModule instance\n",
        "class DetectionModel(pl.LightningModule):\n",
        "    def __init__(self,model: nn.Module, hparams: argparse.Namespace) -> None:\n",
        "        super(DetectionModel, self).__init__()\n",
        "        self.model = model\n",
        "        self.hparams = hparams\n",
        "\n",
        "    @property\n",
        "    def num_batches(self) -> List:\n",
        "        return [len(self.hparams.train_dl), len(self.hparams.val_dl), len(self.hparams.test_dl)]\n",
        "\n",
        "    ######## Configure Optimizer & Schedulers #############\n",
        "    def configure_optimizers(self, *args, **kwargs):\n",
        "        \"instatiate optimizer & scheduler(s)\" \n",
        "        # optimizer\n",
        "        optimizer = self.hparams.optimizer\n",
        "        # scheduler\n",
        "        scheduler = self.hparams.scheduler\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    ############# Train ##############\n",
        "    def train_dataloader(self, *args, **kwargs):\n",
        "        return self.hparams.train_dl\n",
        "\n",
        "    def forward(self, xb, *args, **kwargs):\n",
        "        return self.model(xb)\n",
        "\n",
        "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        loss_dict = self.model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        return {\"loss\": losses, \"log\": loss_dict, \"progress_bar\": loss_dict}\n",
        "\n",
        "    ############# Validation ##############\n",
        "    def val_dataloader(self, *args, **kwargs):\n",
        "        loader = self.hparams.val_dl\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.coco_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.coco_evaluator.update(res)\n",
        "        return {}\n",
        "\n",
        "\n",
        "    def validation_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.coco_evaluator.accumulate()\n",
        "        self.coco_evaluator.summarize()\n",
        "        metric = self.coco_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"COCO_mAP\": metric}\n",
        "        return {\"COCO_mAP\": metric, \"log\": logs, \"progress_bar\": logs,}\n",
        "    \n",
        "    ############# Test ##############\n",
        "    def test_dataloader(self, *args, **kwargs):\n",
        "        loader = self.hparams.test_dl\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.test_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def test_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.test_evaluator.update(res)\n",
        "        return {}\n",
        "    \n",
        "    def test_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.test_evaluator.accumulate()\n",
        "        self.test_evaluator.summarize()\n",
        "        metric = self.test_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"COCO_mAP\": metric}\n",
        "        return {\"COCO_mAP\": metric, \"log\": logs, \"progress_bar\": logs,}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LWyLxqLTMlB",
        "colab_type": "text"
      },
      "source": [
        "**Some Helper Functions :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzNHc8SjFFyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataloaders(\n",
        "    trn_df: pd.DataFrame, # train dataframe\n",
        "    val_df: pd.DataFrame, # valid dataframe\n",
        "    test_df: pd.DataFrame, # test dataframe\n",
        "    trn_tfms: A.Compose, # transformations to apply to the train dataset\n",
        "    val_tfms: A.Compose, # transformations to apply to the valid and test dataset\n",
        "    trn_bs: int, # train batch size\n",
        "    val_bs: int, # batch size for validaiton and test datasets\n",
        "    ) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    \n",
        "    # Instatiate the Detections Datasets\n",
        "    train_ds = DetectionDataset(trn_df, trn_tfms)\n",
        "    val_ds = DetectionDataset(val_df, val_tfms)\n",
        "    test_ds = DetectionDataset(test_df, val_tfms)\n",
        "    \n",
        "    # Instatiate the dataloaders\n",
        "    train_dl = DataLoader(train_ds, batch_size=trn_bs,shuffle=True, collate_fn=collate_fn, pin_memory=True,)\n",
        "    \n",
        "    val_dl = DataLoader(val_ds, batch_size=val_bs, shuffle=False, collate_fn=collate_fn, pin_memory=False,)\n",
        "    \n",
        "    test_dl = DataLoader(test_ds, batch_size=val_bs, shuffle=False, collate_fn=collate_fn, pin_memory=False,)\n",
        "    # return dataloaders\n",
        "    return train_dl, val_dl, test_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l9FUAt4U1Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(\n",
        "    lr: float, # Learning rate\n",
        "    num_epochs: int,  # number of epochs to train for\n",
        "    nc: int, # number if classes in the dataset\n",
        "    df_train: pd.DataFrame, # train dataframe\n",
        "    df_val: pd.DataFrame, # validation dataframe\n",
        "    df_test: pd.DataFrame, # test dataframe\n",
        "    trn_tfms: A.Compose, # transformations to apply to the train dataset\n",
        "    val_tfms: A.Compose, # transformations to apply to the valid and test dataset\n",
        "    trn_bs: int, # train batch_size\n",
        "    val_bs: int, # validation batch_size\n",
        "    bkb: str, # retinanet backbone [currently supports only resnet models]\n",
        "    **kwargs # retinanet model sepcific kwargs\n",
        ") -> pl.LightningModule:\n",
        "\n",
        "    \"\"\"\n",
        "    Creates lightning Module instance from given arguments.\n",
        "\n",
        "    Returns:\n",
        "        1. pl_model (pl.LightningModule)  : a pl.LightningModule instance\n",
        "        2. dataloaders (List[Dataloader]) : list of train, val, test dataloaders\n",
        "        3. hparams ([argparse.Namespace]) : hyperparmeters\n",
        "    \"\"\"\n",
        "    # Load in the DataLoaders\n",
        "    train_dl, val_dl, test_dl = get_dataloaders(df_train, df_val, df_test, trn_tfms, val_tfms, trn_bs, val_bs)\n",
        "    # Instantiate RetinaNet model\n",
        "    model = Retinanet(num_classes=nc, backbone_kind=bkb, **kwargs)\n",
        "\n",
        "    # instantiate optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.AdamW(params, lr, weight_decay=1e-02)\n",
        "    # instantiate scheduler\n",
        "    scheduler = {\n",
        "        \"scheduler\": optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=num_epochs, steps_per_epoch=len(train_dl)),\n",
        "        \"interval\": \"step\",\n",
        "        \"frequency\": 1,\n",
        "        }\n",
        "\n",
        "    # Create Config Dictionary:\n",
        "    conf_dict = {\n",
        "        \"train_dl\": train_dl,\n",
        "        \"val_dl\": val_dl,\n",
        "        \"test_dl\": test_dl,\n",
        "        \"iou_types\": [\"bbox\"],\n",
        "        \"optimizer\": optimizer,\n",
        "        \"scheduler\": scheduler,\n",
        "    }\n",
        "    \n",
        "    hparams = argparse.Namespace(**conf_dict)\n",
        "    # Instantiate lightning module\n",
        "    pl_model = DetectionModel(model, hparams)\n",
        "    dataloaders = [train_dl, val_dl, test_dl] \n",
        "    \n",
        "    return pl_model, dataloaders, hparams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHxK0HPDVO2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_trainer(fname: Union[str, None] = None, **kwargs) -> pl.Trainer:\n",
        "    \"Returns a pl.Trainer instance\"\n",
        "    if fname is None:\n",
        "        fname = \"/content/drive/My Drive/pascal_checkpoints\" \n",
        "    os.makedirs(fname, exist_ok=True)\n",
        "\n",
        "    # Wandb logger: assuming wandb is set-up [Optional]\n",
        "    # wb_name = f\"{time.strftime('%d-%m-||-%I.%M.%S%-p')}\" # change the run name here\n",
        "    # wb_p = \"retinanet-oxford-pets\" # change the project name here\n",
        "    \n",
        "    # wb_logger = WandbLogger(name=wb_name, project=wb_p, anonymous=\"allow\",)\n",
        "\n",
        "    # # Learning_rate logger to monitor learning_rate [Optional]\n",
        "    # lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
        "    \n",
        "    # checkpoint callback\n",
        "    checkpoint_callback = ModelCheckpoint(fname, mode=\"max\", monitor=\"COCO_mAP\", save_top_k=1,)\n",
        "    # early stopping callback\n",
        "    early_stopping_callback = EarlyStopping(mode=\"max\", monitor=\"COCO_mAP\", patience=5,)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = pl.Trainer(\n",
        "        # logger=[wb_logger],\n",
        "        # callbacks=[lr_logger],\n",
        "        num_sanity_val_steps=0,\n",
        "        benchmark=True,\n",
        "        early_stop_callback=early_stopping_callback,\n",
        "        checkpoint_callback=checkpoint_callback,\n",
        "        terminate_on_nan=True,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDMmzm1dmolJ",
        "colab_type": "text"
      },
      "source": [
        "**Set training parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3waORTjNTOuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------------------- #\n",
        "# Training Parameters :\n",
        "# ------------------------------- #\n",
        "TRAIN_BATCH_SIZE = 32 # Batch size for train dataset\n",
        "VALID_BATCH_SIZE = 32 # batch size for valid & test dataset\n",
        "LR = 1e-03 # learning_rate for Optimizer\n",
        "NUM_EPOCHS = 30\n",
        "NUM_CLASSES = 37  # Oxford-IIIT Pets Dataset has 37 classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62lxSQaKmuXs",
        "colab_type": "text"
      },
      "source": [
        "**Grab the model & the trainer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GX7IjCeF9xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab the transforms\n",
        "transforms = get_tfms()\n",
        "trn_tfms = transforms['train']\n",
        "val_tfms = transforms['valid']\n",
        "\n",
        "# Instantiate the model & trainer    \n",
        "retinanet, dataloaders, conf_dict = get_model(\n",
        "    LR,\n",
        "    NUM_EPOCHS,\n",
        "    NUM_CLASSES,\n",
        "    df_trn,\n",
        "    df_val,\n",
        "    df_test,\n",
        "    trn_tfms,\n",
        "    val_tfms,\n",
        "    trn_bs=TRAIN_BATCH_SIZE,\n",
        "    val_bs=VALID_BATCH_SIZE,\n",
        "    bkb=\"resnet18\", # change this if want to use other resnet backbone\n",
        ")\n",
        "\n",
        "trainer = get_trainer(check_val_every_n_epoch=5, gpus=1, precision=16, gradient_clip_val=0.1, max_epochs=NUM_EPOCHS,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDTQBpRhWUJ8",
        "colab_type": "text"
      },
      "source": [
        "**Train model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmwRvRK0GLXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.fit(retinanet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2RsQnnWV38",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ado3NN6GzVsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model on the Test DataLoader\n",
        "# NB: Best weights are automatically loaded\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eZASMzEqIiW",
        "colab_type": "text"
      },
      "source": [
        "**save trained weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVBbx_EqqL9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = '/content/drive/My Drive/resnet18-pets-ver0.0.1.pth'\n",
        "torch.save(retinanet.model.state_dict(), fname, _use_new_zipfile_serialization=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgbi8Yrom3k1",
        "colab_type": "text"
      },
      "source": [
        "**Finetune (Optional):** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2zsOejWph7a",
        "colab_type": "text"
      },
      "source": [
        "**set-up finetune parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJvB2pjpm6JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up new Parameters\n",
        "LR = 1e-05\n",
        "NUM_EPOCHS = 22\n",
        "\n",
        "retinanet.model.requires_grad_(True)\n",
        "params = [p for p in retinanet.model.parameters() if p.requires_grad]\n",
        "# Instantiate Optimizer\n",
        "optimizer = optim.AdamW(params, weight_decay=1e-02)\n",
        "\n",
        "# instantiate scheduler\n",
        "scheduler = {\n",
        "    \"scheduler\": optim.lr_scheduler.OneCycleLR(optimizer, LR, epochs=NUM_EPOCHS, steps_per_epoch=len(conf_dict.train_dl)),\n",
        "    \"interval\": \"step\",\n",
        "    \"frequency\": 1,\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c8z-JU0HmkZ",
        "colab_type": "text"
      },
      "source": [
        "**Update the configuration:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRp63DmRm6QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the parameters of the conf_dict\n",
        "conf_dict.optimizer = optimizer\n",
        "conf_dict.scheduler = scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1vTbuecHrR-",
        "colab_type": "text"
      },
      "source": [
        "**Update trainer & model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC6xG1J5rt1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: make it more effective\n",
        "\n",
        "# Reinstantiate model\n",
        "retinanet_2 = DetectionModel(retinanet.model, conf_dict)\n",
        "retinanet_2.model.load_state_dict(torch.load(fname))\n",
        "\n",
        "# Reinstantiate trainer\n",
        "trainer_2 = get_trainer(check_val_every_n_epoch=5, gpus=1, precision=16, gradient_clip_val=0.1, max_epochs=NUM_EPOCHS,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4AOV8ZSpn__",
        "colab_type": "text"
      },
      "source": [
        "**Train**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgYtbHjypoEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer_2.fit(retinanet_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4J5ReMQpoH6",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate on test data**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7jKIEkbpoQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer_2.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2qU12ERHxaX",
        "colab_type": "text"
      },
      "source": [
        "**save model weights:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py82mYS6HwfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = '/content/drive/My Drive/resnet18-pets-ver0.0.2.pth'\n",
        "torch.save(retinanet.model.state_dict(), fname, _use_new_zipfile_serialization=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIjTsmOovxo",
        "colab_type": "text"
      },
      "source": [
        "**Inference**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpzx3tTFXAAS",
        "colab_type": "text"
      },
      "source": [
        "**Load in a `torch` model to do inference:**  \n",
        "\n",
        "**Model weights can be loaded in 2 ways either load the weights trained above in that case set fname to be the `path` to where the `state_dict` is saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0B34LISdMTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate Torch Model for Inference\n",
        "m = Retinanet(num_classes=37, backbone_kind='resnet18')\n",
        "\n",
        "# Load in the pretrained model weights from weights file\n",
        "fname = None\n",
        "m.load_state_dict(torch.load(fname))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvNGuw82IXGY",
        "colab_type": "text"
      },
      "source": [
        "**To load model weights from already trained weights that are available [here](https://github.com/benihime91/retinanet_pet_detector/releases).**  \n",
        "\n",
        "**Uncomment the cell given below.**  \n",
        "**Copy the `url` of the weights file and set the url to be the one copied.**\n",
        "**If using `GPU` set device to be `gpu` else set it to be `cpu`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbsHl_9-I40-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# url = None\n",
        "# device = 'gpu'\n",
        "\n",
        "# # load model state_dict from url\n",
        "# state_dict = torch.hub.load_state_dict_from_url(url, map_location=device)\n",
        "# m.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjtcQAvbXNi9",
        "colab_type": "text"
      },
      "source": [
        "**import & helper functions for inference:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOM64wy_dqT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from torchvision.ops.boxes import batched_nms\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_tfms = A.Compose([A.ToFloat(max_value=255.0, always_apply=True), ToTensorV2(always_apply=True),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is1_vzXkeesg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def get_preds(\n",
        "    model: Union[nn.Module, pl.LightningModule],\n",
        "    path: str,\n",
        "    threshold: float,\n",
        "    iou_threshold: float,\n",
        "    device: torch.device,\n",
        ") -> Tuple[List, List, List]:\n",
        "    \"Get predictions on image\"\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    # Load the imag\n",
        "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    # Process the image\n",
        "    img = test_tfms(image=img)[\"image\"]\n",
        "    img = img.to(device)\n",
        "    # Generate predictions\n",
        "    model.eval()\n",
        "    pred = model([img])\n",
        "\n",
        "    # Gather the bbox, scores & labels from the preds\n",
        "    pred_boxes = pred[0][\"boxes\"]  # Bounding boxes\n",
        "    pred_class = pred[0][\"labels\"]  # predicted class labels\n",
        "    pred_score = pred[0][\"scores\"]  # predicted scores\n",
        "    # Get list of index with score greater than threshold.\n",
        "    mask = pred_score > threshold\n",
        "    # Filter predictions\n",
        "    boxes = pred_boxes[mask]\n",
        "    clas = pred_class[mask]\n",
        "    scores = pred_score[mask]\n",
        "\n",
        "    # do NMS\n",
        "    keep_idxs = batched_nms(boxes, scores, clas, iou_threshold)\n",
        "    boxes = list(boxes[keep_idxs].cpu().numpy())\n",
        "    clas = list(clas[keep_idxs].cpu().numpy())\n",
        "    scores = list(scores[keep_idxs].cpu().numpy())\n",
        "    return boxes, clas, scores\n",
        "\n",
        "\n",
        "def object_detection_api(\n",
        "    model: Union[nn.Module, pl.LightningModule],\n",
        "    device: torch.device,\n",
        "    img_path: str = None,\n",
        "    score_threshold: float = 0.5,\n",
        "    iou_threshold: float = 0.2,\n",
        ") -> None:\n",
        "    \"Draw bbox predictions on given image at img_pth\"\n",
        "    if img_path is None:\n",
        "        uploaded = files.upload()\n",
        "        img_path = list(uploaded.keys())[0]\n",
        "    print(\"[INFO] Generating predictions ....\")\n",
        "    bb, cls, sc = get_preds(model, img_path, score_threshold, iou_threshold, device,)\n",
        "    print(\"[INFO] Creating bbox on the image .... \")\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "    viz.draw_bboxes(img, boxes=bb, classes=cls, scores=sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvxheUJFXonZ",
        "colab_type": "text"
      },
      "source": [
        "**inference on test images:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Bjihgpe07e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 10 # index of the test_image\n",
        "object_detection_api(m, device=device, score_threshold=0.7, iou_threshold=0.2, img_path=df_test[\"filename\"][idx],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5d_8kNXs-q",
        "colab_type": "text"
      },
      "source": [
        "**inference on user given images:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQnBdkC8v0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference on User Images\n",
        "object_detection_api(m, device=device, score_threshold=0.7, iou_threshold=0.2,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2cgFjk6-awc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}