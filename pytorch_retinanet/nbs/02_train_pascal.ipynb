{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_pascal_2007.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/pytorch_retinanet/blob/master/nbs/02_train_pascal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzwamhncVXkT",
        "colab_type": "text"
      },
      "source": [
        "**Load Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpOoVDioVaf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbvhLAldCPZx",
        "colab_type": "text"
      },
      "source": [
        "**Setup:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6qQWP6i0TCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What GPU do we have ?\n",
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DimpLe6l0ZV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure colab doesn't disconnect\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzKR4Mas0bts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies\n",
        "! pip install pytorch-lightning wandb\n",
        "! pip install git+https://github.com/albumentations-team/albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM345So_0db0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab the Data\n",
        "! unzip -qq /content/drive/My\\ Drive/Pascal\\ 2007\\ Data/pascal_voc_2007_test.zip\n",
        "! unzip -qq /content/drive/My\\ Drive/Pascal\\ 2007\\ Data/pascal_voc_2007_train_val.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVy453Kj0ezz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the RetinaNet Repo:\n",
        "! git clone https://github.com/benihime91/pytorch_retinanet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqeLNykuVoam",
        "colab_type": "text"
      },
      "source": [
        "**wandb login:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKMiEqQnZiP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use wandb to track experiments : Comment this if not using wandb logger\n",
        "! wanbd login # a74f67fd5fae293e301ea8b6710ee0241f595a63"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yydM5YwaVhbL",
        "colab_type": "text"
      },
      "source": [
        "**Standard imports:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXn7Cf1B0gUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "from typing import *\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNIGOfxd07r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import (EarlyStopping, ModelCheckpoint,LearningRateLogger,)\n",
        "\n",
        "from pytorch_retinanet.src.models import Retinanet\n",
        "from pytorch_retinanet.src.utils.eval_utils import CocoEvaluator\n",
        "from pytorch_retinanet.src.utils.eval_utils import get_coco_api_from_dataset\n",
        "from pytorch_retinanet.src.utils.general_utils import collate_fn\n",
        "from pytorch_retinanet import DetectionDataset, Visualizer\n",
        "\n",
        "pl.seed_everything(123)\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO0MlXYB__-A",
        "colab_type": "text"
      },
      "source": [
        "**Load in the Data:**  \n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/benihime91/pytorch_retinanet/blob/master/nbs/01_preprocess_pascal.ipynb)     \n",
        "[01_preprocess_pascal.ipynb](https://github.com/benihime91/pytorch_retinanet/blob/master/nbs/01_preprocess_pascal.ipynb) : notebook to preprocess the `PascalVOC2007`data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEL2Ad5f2nag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_df = pd.read_csv('/content/drive/My Drive/Pascal 2007 Data/trn_data.csv')\n",
        "val_df = pd.read_csv('/content/drive/My Drive/Pascal 2007 Data/val_data.csv')\n",
        "tst_df = pd.read_csv('/content/drive/My Drive/Pascal 2007 Data/tst_data.csv')\n",
        "\n",
        "# Load in the Label Dict\n",
        "label_dict = pickle.load(open(\"/content/drive/My Drive/Pascal 2007 Data/names.pkl\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R9EZZH9-rYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_df.head() # train dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g9OjRgQZuB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_df.head() # validation dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHK-ClX6ZwOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tst_df.head() # test dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEgZt63rZzx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict # a dictionary which stores the mapping of target_labels to class_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsLCGIguYfUF",
        "colab_type": "text"
      },
      "source": [
        "**Utility function to display a random image from a pandas dataframe with bounding boxes:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLQ9dP3J29Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the visualizer\n",
        "viz = Visualizer(class_names=label_dict)\n",
        "\n",
        "def display_random_image(df: pd.DataFrame) -> None:\n",
        "    \"displays a radom Image from given dataframe\"\n",
        "    n = np.random.randint(0, len(df))\n",
        "    fname = df[\"filename\"][n]\n",
        "    boxes = df.loc[df[\"filename\"] == fname][[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "    labels = df.loc[df[\"filename\"] == fname][\"labels\"].values\n",
        "    viz.draw_bboxes(fname, boxes=boxes, classes=labels, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afBCaCgLYX48",
        "colab_type": "text"
      },
      "source": [
        "**Sanity Check : Display image from the data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWzs5PpH3CEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display random Image from the train set\n",
        "display_random_image(trn_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-YWqtF-gf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display random Image from the validation set\n",
        "display_random_image(val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9wMRVsd-kUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display random Image from the Test Dataset\n",
        "display_random_image(tst_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWqI1lhh6cC1",
        "colab_type": "text"
      },
      "source": [
        "**Instantiate `transforms`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV_zkqs_3GnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tfms() -> Dict[str, A.Compose]:\n",
        "    \"Returns a dictionary contatining transformations for train & valid/test datasets\"\n",
        "    \n",
        "    # train transformations : [Modify this to add Transformations to train dataset] \n",
        "    train_transformations = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomSizedBBoxSafeCrop(600, 600, erosion_rate=0.2, p=0.3),\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),\n",
        "    ]\n",
        "\n",
        "    # validation transformations : [Transformations to the validation dataset]\n",
        "    val_tfms = [\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),\n",
        "    ]\n",
        "\n",
        "    # test transformations : [Transformations to the test dataset]\n",
        "    tst_tfms = [\n",
        "        A.ToFloat(max_value=255.0, always_apply=True),\n",
        "        ToTensorV2(always_apply=True),                \n",
        "    ]\n",
        "\n",
        "    # transforms dictionary :\n",
        "    transforms = {\n",
        "        \"train\": A.Compose(trn_tfms, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),),\n",
        "        \"valid\": A.Compose(val_tfms, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),),\n",
        "        \"test\" : A.Compose(tst_tfms, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),),\n",
        "    }\n",
        "    \n",
        "    return transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OZIC6bN6VQZ",
        "colab_type": "text"
      },
      "source": [
        "**Create `pl.LightningModule` instance :** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tw0PB184LEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create pl.LightningModule instance\n",
        "\n",
        "# ========\n",
        "# INFO :\n",
        "# ========\n",
        "# The hparams config file should contain the following :\n",
        "# ========\n",
        "# 1. optimizer : torch.optim.Optimizer -> Optimizer for the model\n",
        "# 2. scheduler : Union[torch.optim.lr_scheduler, None] -> Scheduler for the Optimizer\n",
        "\n",
        "# 3. trn_df    : pandas.DataFrame -> train dataframe\n",
        "# 4. trn_bs    : int -> train batch_size\n",
        "\n",
        "# 5. val_df    : pandas.DataFrame -> validation dataframe\n",
        "# 6. val_bs    : int -> validation batch_size\n",
        "\n",
        "# 7. test_df   :  pandas.DataFrame -> test dataframe\n",
        "# 8. test_bs   : int -> test batch_size\n",
        "\n",
        "# 9. iou_types : List -> for coco evaluation set it to [\"bbox\"].\n",
        "\n",
        "class DetectionModel(pl.LightningModule):\n",
        "    def __init__(self,model: nn.Module, hparams: argparse.Namespace) -> None:\n",
        "        super(DetectionModel, self).__init__()\n",
        "        self.model = model\n",
        "        self.hparams = hparams\n",
        "\n",
        "    @property\n",
        "    def num_batches(self) -> List:\n",
        "        \"returns a list containing the number of batches in train, val & test dataloaders\"\n",
        "        return [len(self.train_dataloader()), len(self.val_dataloader()), len(self.test_dataloader())]\n",
        "\n",
        "    ######## Configure Optimizer & Schedulers #############\n",
        "    def configure_optimizers(self, *args, **kwargs):\n",
        "        \"instatiate optimizer & scheduler(s)\" \n",
        "        # optimizer\n",
        "        optimizer = self.hparams.optimizer\n",
        "        # scheduler\n",
        "        scheduler = self.hparams.scheduler\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            return [optimizer], [scheduler]\n",
        "        else:\n",
        "            return [optimizer]\n",
        "\n",
        "    ############# Forward Pass of the Model ##############\n",
        "    def forward(self, xb, *args, **kwargs):\n",
        "        \"forward step\"\n",
        "        return self.model(xb)\n",
        "\n",
        "    ############### preprare data #########################\n",
        "    def setup(self, stage=None):\n",
        "        # Instantiate Transforms:\n",
        "        self.tfms    = get_tfms()\n",
        "        # Load in the DataFrames\n",
        "        self.trn_df  = pd.read_csv(self.hparams.trn_df)\n",
        "        self.val_df  = pd.read_csv(self.hparams.val_df)\n",
        "        self.test_df = pd.read_csv(self.hparams.test_df)\n",
        "\n",
        "    ############# Train ##############\n",
        "    def train_dataloader(self, *args, **kwargs):\n",
        "        \"instantiate train dataloader\" \n",
        "        train_ds = DetectionDataset(self.trn_df, self.tfms['train'])\n",
        "        trn_dl = DataLoader(\n",
        "            train_ds, batch_size=self.hparams.trn_bs, shuffle=True, collate_fn=collate_fn, pin_memory=True,\n",
        "            )\n",
        "        \n",
        "        return trn_dl\n",
        "\n",
        "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        \"one training step\"\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        loss_dict = self.model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        return {\"loss\": losses, \"log\": loss_dict, \"progress_bar\": loss_dict}\n",
        "\n",
        "    ############# Validation ##############\n",
        "    def val_dataloader(self, *args, **kwargs):\n",
        "        \"instatiate validation dataloader\"\n",
        "        val_ds = DetectionDataset(self.val_df, self.tfms['valid'])\n",
        "        loader = DataLoader(val_ds, batch_size=self.hparams.val_bs, shuffle=False, collate_fn=collate_fn,)\n",
        "        # instantiate coco_api to track metrics\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.coco_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        \"one validation step\"\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.coco_evaluator.update(res)\n",
        "        return {}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.coco_evaluator.accumulate()\n",
        "        self.coco_evaluator.summarize()\n",
        "        metric = self.coco_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"mAP\": metric}\n",
        "        return {\"mAP\": metric, \"log\": logs, \"progress_bar\": logs,}\n",
        "    \n",
        "    ############# Test ##############\n",
        "    def test_dataloader(self, *args, **kwargs):\n",
        "        \"instatiate validation dataloader\"\n",
        "        test_ds = DetectionDataset(self.test_df, self.tfms['test'])\n",
        "        loader = DataLoader(test_ds, batch_size=self.hparams.test_bs, shuffle=False, collate_fn=collate_fn,)\n",
        "        # instantiate coco_api to track metrics\n",
        "        coco = get_coco_api_from_dataset(loader.dataset)\n",
        "        self.test_evaluator = CocoEvaluator(coco, self.hparams.iou_types)\n",
        "        return loader\n",
        "\n",
        "    def test_step(self, batch, batch_idx, *args, **kwargs):\n",
        "        \"one test step\"\n",
        "        images, targets, _ = batch\n",
        "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "        outputs = self.model(images, targets)\n",
        "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
        "        self.test_evaluator.update(res)\n",
        "        return {}\n",
        "    \n",
        "    def test_epoch_end(self, outputs, *args, **kwargs):\n",
        "        self.test_evaluator.accumulate()\n",
        "        self.test_evaluator.summarize()\n",
        "        metric = self.test_evaluator.coco_eval[\"bbox\"].stats[0]\n",
        "        metric = torch.as_tensor(metric)\n",
        "        logs = {\"mAP\": metric}\n",
        "        return {\"mAP\": metric, \"log\": logs, \"progress_bar\": logs,}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHUhONui6nd1",
        "colab_type": "text"
      },
      "source": [
        "**Specify Configs:**\n",
        "\n",
        "\n",
        "\n",
        "**Configs for DetectionModel :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tweLPLKIWWuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================= #\n",
        "# Specify Patametrs for the DetectionModel:\n",
        "# ============================================= #\n",
        "\n",
        "# load in the RetinaNet model\n",
        "NUM_CLASSES = 20  # Pascal 2207 Dataset has 20 classes\n",
        "BACKBONE = 'resnet50' # backbone for RetinaNet Model\n",
        "model = Retinanet(num_classes=NUM_CLASSES, backbone_kind=BACKBONE)\n",
        "\n",
        "# instantiate optimizer\n",
        "LR = 1e-02 # learning rate for Optimizer\n",
        "MOMENTUM = 0.9 # Momentum for the Optimizer\n",
        "WEIGHT_DECAY = 0.0001 # Weight Decay for Optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = SGD(params, LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM)\n",
        "\n",
        "# Instantiate scheduler\n",
        "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "# convert scheduler to lightning format\n",
        "INTERVAL = \"step\" # scheduler interval wether after each 'step' for each 'epoch'\n",
        "scheduler = {\"scheduler\": scheduler, \"interval\": INTERVAL , \"frequency\": 1,}\n",
        "\n",
        "# Train dataset Parametrs:\n",
        "trn_df = \"/content/drive/My Drive/Pascal 2007 Data/trn_data.csv\" # path 2 dataframe\n",
        "trn_bs = 32 # batch_size\n",
        "\n",
        "# Valid dataset parametrs:\n",
        "val_df = \"/content/drive/My Drive/Pascal 2007 Data/val_data.csv\" # path 2 dataframe\n",
        "val_bs = 32 # batch_size\n",
        "\n",
        "# Test dataset parametrs:\n",
        "test_df = \"/content/drive/My Drive/Pascal 2007 Data/tst_data.csv\" # path 2 dataframe\n",
        "test_bs = 32 # batch_size\n",
        "\n",
        "# set iou types:\n",
        "iou_types = ['bbox']\n",
        "\n",
        "\n",
        "# Create arguments:\n",
        "hparams = {\n",
        "    'optimizer': optimizer,\n",
        "    'scheduler': scheduler,\n",
        "    'trn_df' : trn_df,\n",
        "    'trn_bs': trn_bs,\n",
        "    'val_df' : val_df,\n",
        "    'val_bs': val_bs,\n",
        "    'test_df' : test_df,\n",
        "    'test_bs': test_bs,\n",
        "    'iou_types': iou_types,\n",
        "}\n",
        "\n",
        "# Convert dictionary to args\n",
        "hparams= argparse.Namespace(**hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37oFgGneWsAU",
        "colab_type": "text"
      },
      "source": [
        "**Configs for LightningTrainer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPutRiTL7Als",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================= #\n",
        "# Create configs for lighntning trainer\n",
        "# ============================================= #\n",
        "\n",
        "# Wandb logger: assuming wandb is set-up [Optional]\n",
        "wb_name = f\"{time.strftime('%d-%m-||-%I.%M.%S%-p')}\" # change the run name here\n",
        "wb_p = \"pascal-2007\" # change the project name here\n",
        "wb_logger = WandbLogger(name=wb_name, project=wb_p, anonymous=\"allow\",)\n",
        "\n",
        "# learning_rate logger:\n",
        "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
        "\n",
        "# set callbacks & loggers:\n",
        "logger=[wb_logger]\n",
        "callbacks=[lr_logger]\n",
        "\n",
        "# checkpoint callback\n",
        "fname = \"/content/drive/My Drive/pascal_checkpoints\" \n",
        "os.makedirs(fname, exist_ok=True)\n",
        "checkpoint_callback = ModelCheckpoint(fname, mode=\"max\", monitor=\"mAP\", save_top_k=1,)\n",
        "\n",
        "# early stopping callback\n",
        "early_stop_callback = EarlyStopping(mode=\"max\", monitor=\"mAP\", patience=5,)\n",
        "\n",
        "check_val_every_n_epoch=5 # Validaiton Check Interval\n",
        "gpus=1  # gpus to use\n",
        "precision=16 # precision\n",
        "max_epochs=NUM_EPOCHS # Total number of Epochs\n",
        "\n",
        "# Cconvert trainer flags into a dictionary\n",
        "trainer_config = {\n",
        "    'logger': logger,\n",
        "    'callbacks': callbacks,\n",
        "    'checkpoint_callback': checkpoint_callback,\n",
        "    'early_stop_callback' : early_stop_callback,\n",
        "    'gpus': gpus,\n",
        "    'precision': precision,\n",
        "    'max_epochs': max_epochs,\n",
        "    'check_val_every_n_epoch': check_val_every_n_epoch,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqnz8Y-jXNLv",
        "colab_type": "text"
      },
      "source": [
        "**Grab the model & the trainer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcLKfOqzXO74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retinanet = DetectionModel(model, hparams)\n",
        "\n",
        "trainer = pl.Trainer(**trainer_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73_BgwVj6tY2",
        "colab_type": "text"
      },
      "source": [
        "**Train model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U09Swxi17-ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit Model \n",
        "trainer.fit(retinanet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDaMutnjJ6Zt",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba5L5lkf68vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model on the Test DataLoader\n",
        "# NB: Best weights are automatically loaded\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLi6HwhlXUpQ",
        "colab_type": "text"
      },
      "source": [
        "**save trained weights:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evuNIU-pXYGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = '/content/drive/My Drive/resnet50-pascal-ver0.0.1.pth'\n",
        "torch.save(retinanet.model.state_dict(), fname, _use_new_zipfile_serialization=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2RsQnnWV38",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ado3NN6GzVsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model on the Test DataLoader\n",
        "# NB: Best weights are automatically loaded\n",
        "trainer.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIjTsmOovxo",
        "colab_type": "text"
      },
      "source": [
        "**Inference**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpzx3tTFXAAS",
        "colab_type": "text"
      },
      "source": [
        "**Load in a `torch` model to do inference:**  \n",
        "\n",
        "**Model weights can be loaded in 2 ways either load the weights trained above in that case set fname to be the `path` to where the `state_dict` is saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0B34LISdMTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate Torch Model for Inference\n",
        "m = Retinanet(num_classes=37, backbone_kind='resnet18')\n",
        "\n",
        "# Load in the pretrained model weights from weights file\n",
        "fname = None\n",
        "m.load_state_dict(torch.load(fname))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbsHl_9-I40-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# url = None\n",
        "# device = 'gpu'\n",
        "\n",
        "# # load model state_dict from url\n",
        "# state_dict = torch.hub.load_state_dict_from_url(url, map_location=device)\n",
        "# m.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjtcQAvbXNi9",
        "colab_type": "text"
      },
      "source": [
        "**import & helper functions for inference:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOM64wy_dqT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from torchvision.ops.boxes import batched_nms\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_tfms = A.Compose([A.ToFloat(max_value=255.0, always_apply=True), ToTensorV2(always_apply=True),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is1_vzXkeesg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def get_preds(\n",
        "    model: Union[nn.Module, pl.LightningModule],\n",
        "    path: str,\n",
        "    threshold: float,\n",
        "    iou_threshold: float,\n",
        "    device: torch.device,\n",
        ") -> Tuple[List, List, List]:\n",
        "    \"Get predictions on image\"\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    # Load the imag\n",
        "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    # Process the image\n",
        "    img = test_tfms(image=img)[\"image\"]\n",
        "    img = img.to(device)\n",
        "    # Generate predictions\n",
        "    model.eval()\n",
        "    pred = model([img])\n",
        "\n",
        "    # Gather the bbox, scores & labels from the preds\n",
        "    pred_boxes = pred[0][\"boxes\"]  # Bounding boxes\n",
        "    pred_class = pred[0][\"labels\"]  # predicted class labels\n",
        "    pred_score = pred[0][\"scores\"]  # predicted scores\n",
        "    # Get list of index with score greater than threshold.\n",
        "    mask = pred_score > threshold\n",
        "    # Filter predictions\n",
        "    boxes = pred_boxes[mask]\n",
        "    clas = pred_class[mask]\n",
        "    scores = pred_score[mask]\n",
        "\n",
        "    # do NMS\n",
        "    keep_idxs = batched_nms(boxes, scores, clas, iou_threshold)\n",
        "    boxes = list(boxes[keep_idxs].cpu().numpy())\n",
        "    clas = list(clas[keep_idxs].cpu().numpy())\n",
        "    scores = list(scores[keep_idxs].cpu().numpy())\n",
        "    return boxes, clas, scores\n",
        "\n",
        "\n",
        "def object_detection_api(\n",
        "    model: Union[nn.Module, pl.LightningModule],\n",
        "    device: torch.device,\n",
        "    img_path: str = None,\n",
        "    score_threshold: float = 0.5,\n",
        "    iou_threshold: float = 0.2,\n",
        ") -> None:\n",
        "    \"Draw bbox predictions on given image at img_pth\"\n",
        "    if img_path is None:\n",
        "        uploaded = files.upload()\n",
        "        img_path = list(uploaded.keys())[0]\n",
        "    print(\"[INFO] Generating predictions ....\")\n",
        "    bb, cls, sc = get_preds(model, img_path, score_threshold, iou_threshold, device,)\n",
        "    print(\"[INFO] Creating bbox on the image .... \")\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "    viz.draw_bboxes(img, boxes=bb, classes=cls, scores=sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvxheUJFXonZ",
        "colab_type": "text"
      },
      "source": [
        "**inference on test images:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Bjihgpe07e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 10 # index of the test_image\n",
        "object_detection_api(m, device=device, score_threshold=0.7, iou_threshold=0.2, img_path=df_test[\"filename\"][idx],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5d_8kNXs-q",
        "colab_type": "text"
      },
      "source": [
        "**inference on user given images:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQnBdkC8v0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference on User Images\n",
        "object_detection_api(m, device=device, score_threshold=0.7, iou_threshold=0.2,)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}